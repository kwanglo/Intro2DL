{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "combined_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMZfhu7XKc9AZwFOmyLgy6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwanglo/mge51101-20195171/blob/master/final_project/combined_CNN_fastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv8ZMQS9dr5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "95ccf18d-73b3-4f24-c22a-0beb28977ffe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWBmpvaLd9Nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "31db6af2-d690-453b-de5b-8c3a9eeff1bc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 19 06:51:04 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plvd7H_seCML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install konlpy\n",
        "!pip3 install soynlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOl46e9beMHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "from sklearn import datasets, model_selection\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO5Vo2CxeQPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/gdrive/My Drive/Colab Notebooks/Final Project/dataset/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3MX4jXMeuZ6",
        "colab_type": "text"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD4Muf7YhA1i",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing - Emotion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oVN6ccTg1VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "from soynlp.normalizer import *\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "def tokenizer(text): # create a tokenizer function\n",
        "    okt = Okt()\n",
        "    text = only_hangle(text)\n",
        "    text = repeat_normalize(text, num_repeats = 2)\n",
        "    x = okt.morphs(text , stem= True)\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOw3Ww5nhGID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words_set = pd.read_csv(path+'stopwords100.txt',header = 0, delimiter = '\\t', quoting = 3)\n",
        "stop_words= (list(stop_words_set['aa']))\n",
        "stop_words2 = ['은', '는', '이', '가', '하', '아', '것', '들','의', '있', '되', '수', '보', '주', '등', '한']\n",
        "stop_words.extend(stop_words)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMbhpZmuhIRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "SEED = 3432\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "TEXT_emo = data.Field(tokenize=tokenizer, stop_words = stop_words)\n",
        "LABEL_emo = data.LabelField()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA6722Q_kYG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R99Oem4k0St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "fields_emo = [(\"Sentence\", TEXT_emo),(\"Emotion\", LABEL_emo)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HokxYlu_k3oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_emo,valid_emo, test_emo = data.TabularDataset.splits(\n",
        "                                        path = path,\n",
        "                                        train = 'sentiment_train.csv',\n",
        "                                        validation = 'sentiment_valid.csv',\n",
        "                                        test = 'sentiment_test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields_emo,\n",
        "                                        skip_header = True\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-suCA51k8Gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0e1aa0c-54c5-41d4-b5fc-586fe6137e76"
      },
      "source": [
        "vars(train_emo[3])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Emotion': '5', 'Sentence': ['어제', '런닝맨', '완전', '재밌다']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpV_SIrfllGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "vec = torchtext.vocab.Vectors('wiki.ko.vec', cache=path)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz6r-BUelogp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT_emo.build_vocab(train_emo, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = vec, \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL_emo.build_vocab(train_emo)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EEHQvW8lunB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Iterator, BucketIterator\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator_emo, valid_iterator_emo, test_iterator_emo = data.BucketIterator.splits(\n",
        "    (train_emo, valid_emo, test_emo), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device, sort = False)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ0BXF_KmDk0",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing - Utterance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qczuf5A64CbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 3432\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT_utt = data.Field(tokenize=tokenizer, stop_words = stop_words)\n",
        "LABEL_utt = data.LabelField()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0wp4Q6Dl8nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields_utt = [(\"text\", TEXT_utt),(\"label\", LABEL_utt)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41qPXuw0maM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_utt,valid_utt, test_utt = data.TabularDataset.splits(\n",
        "                                        path = path,\n",
        "                                        train = 'utterance_train.csv',\n",
        "                                        validation = 'utterance_valid.csv',\n",
        "                                        test = 'utterance_test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields_utt,\n",
        "                                        skip_header = True\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTRN7TW2mvMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT_utt.build_vocab(train_utt, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = vec, \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL_utt.build_vocab(train_utt)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNClEjcUwXg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator_utt, valid_iterator_utt, test_iterator_utt = data.BucketIterator.splits(\n",
        "    (train_utt, valid_utt, test_utt), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device, sort = False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYsJjjn6nE_j",
        "colab_type": "text"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyXp6hyjm9ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_emo(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        text = text.permute(1, 0)        \n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoBHi_3pnJkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_utt(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        text = text.permute(1, 0)        \n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKUzNV6AnQPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM_emo = len(TEXT_emo.vocab)\n",
        "OUTPUT_DIM_emo = len(LABEL_emo.vocab)\n",
        "PAD_IDX_emo = TEXT_emo.vocab.stoi[TEXT_emo.pad_token]\n",
        "\n",
        "INPUT_DIM_utt = len(TEXT_utt.vocab)\n",
        "OUTPUT_DIM_utt = len(LABEL_utt.vocab)\n",
        "PAD_IDX_utt = TEXT_utt.vocab.stoi[TEXT_utt.pad_token]\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,4]\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model_emo = CNN_emo(INPUT_DIM_emo, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM_emo, DROPOUT, PAD_IDX_emo)\n",
        "model_utt = CNN_utt(INPUT_DIM_utt, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM_utt, DROPOUT, PAD_IDX_utt)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5HzKE_pn9L8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9a050e9-d03b-4a1e-ec88-759db51642f2"
      },
      "source": [
        "def count_parameters_emo(model_emo):\n",
        "    return sum(p.numel() for p in model_emo.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters_emo(model_emo):,} trainable parameters')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,058,307 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gku5cb9BoFOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a5dfa48-7822-4e4b-b4b6-c5b0a6641828"
      },
      "source": [
        "def count_parameters_utt(model_utt):\n",
        "    return sum(p.numel() for p in model_utt.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters_utt(model_utt):,} trainable parameters')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,218,707 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5hkGTZHoQ5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_embeddings_emo = TEXT_emo.vocab.vectors\n",
        "pretrained_embeddings_utt = TEXT_utt.vocab.vectors"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJx4PmC8oJrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX_emo = TEXT_emo.vocab.stoi[TEXT_emo.unk_token]\n",
        "UNK_IDX_utt = TEXT_utt.vocab.stoi[TEXT_utt.unk_token]\n",
        "\n",
        "model_emo.embedding.weight.data[UNK_IDX_emo] = torch.zeros(EMBEDDING_DIM)\n",
        "model_emo.embedding.weight.data[PAD_IDX_emo] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "model_utt.embedding.weight.data[UNK_IDX_utt] = torch.zeros(EMBEDDING_DIM)\n",
        "model_utt.embedding.weight.data[PAD_IDX_utt] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbpHXbPPo5bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer_emo = optim.Adam(model_emo.parameters())\n",
        "optimizer_utt = optim.Adam(model_utt.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_emo = model_emo.to(device)\n",
        "model_utt = model_utt.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0caTfGaLpEUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SkGvFAb4PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as sk"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLMksDs0pO2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_emo(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.Sentence)\n",
        "        \n",
        "        loss = criterion(predictions, batch.Emotion)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, batch.Emotion)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mykuXo51pTZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model_emo(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    y_pred = []\n",
        "    y_actual = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.Sentence)\n",
        "            pred = torch.max(predictions, 1).indices\n",
        "\n",
        "            pred = pred.tolist()\n",
        "            pred\n",
        "            actual = batch.Emotion.tolist()\n",
        "            actual\n",
        "\n",
        "            loss = criterion(predictions, batch.Emotion)\n",
        "            \n",
        "            acc = categorical_accuracy(predictions, batch.Emotion)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            y_pred = y_pred + pred\n",
        "            y_actual = y_actual + actual\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), y_pred, y_actual"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31SzjxTbtar3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_utt(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text)        \n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3__scl4ctakR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model_utt(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    y_pred = []\n",
        "    y_actual = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text)\n",
        "            pred = torch.max(predictions, 1).indices\n",
        "\n",
        "            pred = pred.tolist()\n",
        "            pred\n",
        "            actual = batch.label.tolist()\n",
        "            actual\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            y_pred = y_pred + pred\n",
        "            y_actual = y_actual + actual\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), y_pred, y_actual"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqcEGa3MpUh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2XsOLCqpXTb",
        "colab_type": "text"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMeltC8PpVru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "d3cab50b-6b7b-4350-852f-997f656f6ba9"
      },
      "source": [
        "#Emotion\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss_emo, train_acc_emo = train_model_emo(model_emo, train_iterator_emo, optimizer_emo, criterion)\n",
        "    valid_loss_emo, valid_acc_emo, y_predict, y_real = evaluate_model_emo(model_emo, valid_iterator_emo, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss_emo < best_valid_loss:\n",
        "        best_valid_loss = valid_loss_emo\n",
        "        torch.save(model_emo.state_dict(), 'emo-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss_emo:.3f} | Train Acc: {train_acc_emo*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss_emo:.3f} |  Val. Acc: {valid_acc_emo*100:.2f}%')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.801 | Train Acc: 70.98%\n",
            "\t Val. Loss: 1.753 |  Val. Acc: 42.19%\n",
            "Epoch: 02 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.666 | Train Acc: 76.25%\n",
            "\t Val. Loss: 1.883 |  Val. Acc: 42.41%\n",
            "Epoch: 03 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.558 | Train Acc: 79.90%\n",
            "\t Val. Loss: 2.030 |  Val. Acc: 42.40%\n",
            "Epoch: 04 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.467 | Train Acc: 83.54%\n",
            "\t Val. Loss: 2.209 |  Val. Acc: 41.96%\n",
            "Epoch: 05 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.413 | Train Acc: 85.55%\n",
            "\t Val. Loss: 2.371 |  Val. Acc: 42.10%\n",
            "Epoch: 06 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.344 | Train Acc: 88.03%\n",
            "\t Val. Loss: 2.565 |  Val. Acc: 41.86%\n",
            "Epoch: 07 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.314 | Train Acc: 89.05%\n",
            "\t Val. Loss: 2.749 |  Val. Acc: 41.69%\n",
            "Epoch: 08 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.287 | Train Acc: 90.25%\n",
            "\t Val. Loss: 2.943 |  Val. Acc: 41.09%\n",
            "Epoch: 09 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.254 | Train Acc: 91.40%\n",
            "\t Val. Loss: 3.125 |  Val. Acc: 41.56%\n",
            "Epoch: 10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.242 | Train Acc: 91.78%\n",
            "\t Val. Loss: 3.285 |  Val. Acc: 42.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQIj6z35rXxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "76c21aca-b1ba-4931-9075-989c1583af69"
      },
      "source": [
        "model_emo.load_state_dict(torch.load('emo-model.pt'))\n",
        "\n",
        "test_loss_emo, test_acc_emo, pred, actual = evaluate_model_emo(model_emo, test_iterator_emo, criterion)\n",
        "\n",
        "f1_score = sk.f1_score(pred,pred, average = 'weighted')\n",
        "print(f'Test Loss: {test_loss_emo:.3f} | Test Acc: {test_acc_emo*100:.2f}% | F1 Score: {f1_score:.2f}')\n",
        "confusion_matrix(actual, pred)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.770 | Test Acc: 42.57% | F1 Score: 1.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 646,  141,  182,  306,  161,  104,  229],\n",
              "       [ 159, 1136,   77,  115,   74,   82,  168],\n",
              "       [ 173,   34,  729,  156,  363,   57,  188],\n",
              "       [ 202,   47,  104,  899,   82,  176,  130],\n",
              "       [ 195,   65,  507,  141,  441,   44,  236],\n",
              "       [ 112,   76,  106,  371,   67,  740,  108],\n",
              "       [ 230,  135,  221,  230,  218,   78,  337]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrRGaZ9r_b6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "3de6c924-d48b-4067-a9da-39cc9aa36bcd"
      },
      "source": [
        "#Utterance\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss_utt, train_acc_utt = train_model_utt(model_utt, train_iterator_utt, optimizer_utt, criterion)\n",
        "    valid_loss_utt, valid_acc_utt, pred, actual = evaluate_model_utt(model_utt, valid_iterator_utt, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss_utt < best_valid_loss:\n",
        "        best_valid_loss = valid_loss_utt\n",
        "        torch.save(model_utt.state_dict(), 'utt-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss_utt:.3f} | Train Acc: {train_acc_utt*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss_utt:.3f} |  Val. Acc: {valid_acc_utt*100:.2f}%')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.737 | Train Acc: 72.83%\n",
            "\t Val. Loss: 1.028 |  Val. Acc: 65.22%\n",
            "Epoch: 02 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.641 | Train Acc: 76.33%\n",
            "\t Val. Loss: 1.084 |  Val. Acc: 65.57%\n",
            "Epoch: 03 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.569 | Train Acc: 79.03%\n",
            "\t Val. Loss: 1.134 |  Val. Acc: 65.09%\n",
            "Epoch: 04 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.501 | Train Acc: 81.49%\n",
            "\t Val. Loss: 1.226 |  Val. Acc: 65.20%\n",
            "Epoch: 05 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.461 | Train Acc: 82.62%\n",
            "\t Val. Loss: 1.306 |  Val. Acc: 65.71%\n",
            "Epoch: 06 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.422 | Train Acc: 84.28%\n",
            "\t Val. Loss: 1.371 |  Val. Acc: 65.04%\n",
            "Epoch: 07 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.392 | Train Acc: 85.09%\n",
            "\t Val. Loss: 1.456 |  Val. Acc: 65.25%\n",
            "Epoch: 08 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.365 | Train Acc: 86.39%\n",
            "\t Val. Loss: 1.550 |  Val. Acc: 64.97%\n",
            "Epoch: 09 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.343 | Train Acc: 86.95%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 64.67%\n",
            "Epoch: 10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.326 | Train Acc: 87.98%\n",
            "\t Val. Loss: 1.644 |  Val. Acc: 64.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LUjWStksw9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c2813969-3027-4106-80be-0a457ce81450"
      },
      "source": [
        "model_utt.load_state_dict(torch.load('utt-model.pt'))\n",
        "\n",
        "test_loss_utt, test_acc_utt, pred, actual = evaluate_model_utt(model_utt, test_iterator_utt, criterion)\n",
        "\n",
        "f1_score = sk.f1_score(pred,pred, average = 'weighted')\n",
        "print(f'Test Loss: {test_loss_emo:.3f} | Test Acc: {test_acc_emo*100:.2f}% | F1 Score: {f1_score:.2f}')\n",
        "confusion_matrix(actual, pred)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.770 | Test Acc: 42.57% | F1 Score: 1.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3998,  709,  460,  264,   74,   45,   30],\n",
              "       [ 616, 3759,  819,   40,   44,   39,    5],\n",
              "       [ 821,  900, 2047,   56,   13,   14,    8],\n",
              "       [ 182,   39,   33, 1506,   10,    4,    6],\n",
              "       [ 324,  130,   76,   32,  397,    6,    3],\n",
              "       [ 274,   78,   27,   25,   24,  101,    1],\n",
              "       [ 165,   31,   24,   13,    3,    3,   99]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHPaPI-um8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emo(model, sentence, min_len = 4):\n",
        "    model.eval()\n",
        "    # 이 부분에서 그냥 바로 tokenizing\n",
        "    tokenized = tokenizer(sentence)\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT_emo.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    preds = model(tensor)\n",
        "    max_preds = preds.argmax(dim = 1)\n",
        "    return max_preds.item()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVEAG6tt9Req",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emotion_classifier(logits):\n",
        "  global sentiment\n",
        "  if logits == \"0\":\n",
        "    sentiment = '중립'\n",
        "  elif logits == \"1\":\n",
        "    sentiment = '공포'\n",
        "  elif logits == \"2\":\n",
        "    sentiment = '놀람'\n",
        "  elif logits == \"3\":\n",
        "    sentiment = '분노'\n",
        "  elif logits == \"4\":\n",
        "    sentiment = '슬픔'\n",
        "  elif logits == \"5\":\n",
        "    sentiment = '행복'\n",
        "  elif logits == \"6\":\n",
        "    sentiment = '혐오'\n",
        "\n",
        "  return sentiment"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbNHks9b9Saj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_utt(model, sentence, min_len = 4):\n",
        "    model.eval()\n",
        "    # 이 부분에서 그냥 바로 tokenizing\n",
        "    tokenized = tokenizer(sentence)\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT_utt.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    preds = model(tensor)\n",
        "    max_preds = preds.argmax(dim = 1)\n",
        "    return max_preds.item()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSTCj55V9aYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def utterance_classifier(logits):\n",
        "  global utterance\n",
        "  if logits == \"0\":\n",
        "    utterance = '미완'\n",
        "  elif logits == \"1\":\n",
        "    utterance = '서술'\n",
        "  elif logits == \"2\":\n",
        "    utterance = '질문'\n",
        "  elif logits == \"3\":\n",
        "    utterance = '요구'\n",
        "  elif logits == \"4\":\n",
        "    utterance = '수사의문'\n",
        "  elif logits == \"5\":\n",
        "    utterance = '수사명령'\n",
        "  elif logits == \"6\":\n",
        "    utterance = '억양'\n",
        "\n",
        "  return utterance"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lslMJKlj9chh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "10255523-5175-4d03-8ebe-06a1cf1f6f47"
      },
      "source": [
        "pred_sentence = input()\n",
        "pred_emo = predict_emo(model_emo, pred_sentence)\n",
        "pred_utt = predict_utt(model_utt, pred_sentence)\n",
        "logit_1 = LABEL_emo.vocab.itos[pred_emo]\n",
        "logit_2 = LABEL_utt.vocab.itos[pred_utt]\n",
        "\n",
        "print(f'이 문장의 감정은 {emotion_classifier(logit_1)}이고, 발화 의도는 {utterance_classifier(logit_2)}입니다')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "프로젝트가 끝나서 너무 기쁘지 않니?\n",
            "이 문장의 감정은 행복이고, 발화 의도는 서술입니다\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
