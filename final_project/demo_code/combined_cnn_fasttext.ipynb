{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "combined_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvXhQ/D6voBrddgVTdtAMv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwanglo/mge51101-20195171/blob/master/final_project/combined_cnn_fasttext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv8ZMQS9dr5t",
        "colab_type": "code",
        "outputId": "29495893-9c9b-4598-d421-34ffed134786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWBmpvaLd9Nc",
        "colab_type": "code",
        "outputId": "f4628e78-4873-4c77-d579-c7efcc85e8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun  7 12:42:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    31W / 250W |    995MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plvd7H_seCML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "699b6533-2e26-4220-ded0-f97635a29c7a"
      },
      "source": [
        "!pip3 install konlpy\n",
        "!pip3 install soynlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.4)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/9b/e115101a833605b3c0e6f3a2bc1f285c95aaa1d93ab808314ca1bde63eed/JPype1-0.7.5-cp36-cp36m-manylinux2010_x86_64.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 56.1MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.6MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Installing collected packages: tweepy, JPype1, beautifulsoup4, colorama, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-0.7.5 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n",
            "Collecting soynlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.18.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->soynlp) (0.15.1)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOl46e9beMHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "from sklearn import datasets, model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from konlpy.tag import Hannanum\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Twitter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO5Vo2CxeQPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/gdrive/My Drive/Colab Notebooks/Final Project/dataset/'\n",
        "data_emo = pd.read_excel(path+\"한국어_단발성_대화_데이터셋.xlsx\")\n",
        "data_utter = pd.read_csv(path+\"fci_data.csv\")\n",
        "train_utter = pd.read_csv(path+\"fci_train.csv\")\n",
        "test_utter = pd.read_csv(path+\"fci_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3MX4jXMeuZ6",
        "colab_type": "text"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ugs-Um1ervu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_emo = data_emo.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4','공포',5468])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjHevDfce1Kq",
        "colab_type": "code",
        "outputId": "aaef2fbd-f451-4185-eccf-021e4ab0c26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data_emo.groupby(\"Emotion\").count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>공포</th>\n",
              "      <td>5468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>놀람</th>\n",
              "      <td>5898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>분노</th>\n",
              "      <td>5665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>슬픔</th>\n",
              "      <td>5267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>중립</th>\n",
              "      <td>4830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>행복</th>\n",
              "      <td>6037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>혐오</th>\n",
              "      <td>5429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Sentence\n",
              "Emotion          \n",
              "공포           5468\n",
              "놀람           5898\n",
              "분노           5665\n",
              "슬픔           5267\n",
              "중립           4830\n",
              "행복           6037\n",
              "혐오           5429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb5K11Ede-dV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Char to int\n",
        "data_emo.loc[(data_emo.Emotion == \"중립\"),\"Emotion\"] = 0\n",
        "data_emo.loc[(data_emo.Emotion == \"공포\"),\"Emotion\"] = 1\n",
        "data_emo.loc[(data_emo.Emotion == \"놀람\"),\"Emotion\"] = 2\n",
        "data_emo.loc[(data_emo.Emotion == \"분노\"),\"Emotion\"] = 3\n",
        "data_emo.loc[(data_emo.Emotion == \"슬픔\"),\"Emotion\"] = 4\n",
        "data_emo.loc[(data_emo.Emotion == \"행복\"),\"Emotion\"] = 5\n",
        "data_emo.loc[(data_emo.Emotion == \"혐오\"),\"Emotion\"] = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr_yrtPlfOEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 숫자로 이미지 나눌때 \n",
        "#중립\n",
        "Neutral = data_emo[data_emo[\"Emotion\"] == 0]\n",
        "#공포\n",
        "Fear = data_emo[data_emo[\"Emotion\"] == 1]\n",
        "Fear.head()\n",
        "#놀람\n",
        "Surprise = data_emo[data_emo[\"Emotion\"] == 2]\n",
        "#분노\n",
        "Anger = data_emo[data_emo[\"Emotion\"] == 3]\n",
        "#슬픔\n",
        "Sad = data_emo[data_emo[\"Emotion\"] == 4]\n",
        "#행복\n",
        "Happy = data_emo[data_emo[\"Emotion\"] == 5]\n",
        "#혐오\n",
        "Disgust = data_emo[data_emo[\"Emotion\"] == 6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSaBlzo6f5Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnd_num = 2020\n",
        "Fear_train = Fear.sample(frac=0.7, random_state=rnd_num)\n",
        "Fear_test = Fear.drop(Fear_train.index)\n",
        "\n",
        "Surprise_train = Surprise.sample(frac=0.7, random_state=rnd_num)\n",
        "Surprise_test = Surprise.drop(Surprise_train.index)\n",
        "\n",
        "Anger_train = Anger.sample(frac=0.7, random_state=rnd_num)\n",
        "Anger_test = Anger.drop(Anger_train.index)\n",
        "\n",
        "Sad_train = Sad.sample(frac=0.7, random_state=rnd_num)\n",
        "Sad_test = Sad.drop(Sad_train.index)\n",
        "\n",
        "Neutral_train = Neutral.sample(frac=0.7, random_state=rnd_num)\n",
        "Neutral_test = Neutral.drop(Neutral_train.index)\n",
        "\n",
        "Happy_train = Happy.sample(frac=0.7, random_state=rnd_num)\n",
        "Happy_test = Happy.drop(Happy_train.index)\n",
        "\n",
        "Disgust_train = Disgust.sample(frac=0.7, random_state=rnd_num)\n",
        "Disgust_test = Disgust.drop(Disgust_train.index)\n",
        "\n",
        "train_emo = pd.concat([Fear_train,Surprise_train,Anger_train,Sad_train,Neutral_train,Happy_train,Disgust_train])\n",
        "test_emo = pd.concat([Fear_test,Surprise_test,Anger_test,Sad_test,Neutral_test,Happy_test,Disgust_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSsBjqz1f9n1",
        "colab_type": "code",
        "outputId": "4b053b60-0e70-4e71-a756-8841896de315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data_utter.groupby(\"label\").count()\n",
        "#Fragments(FR) - 0\n",
        "#Statements(S) - 1\n",
        "#Questions(Q) - 2\n",
        "#Commands(C) - 3\n",
        "#Rhetorical questions(RQ) - 4\n",
        "#Rhetorical commands(RC) - 5\n",
        "#FragmeIntonation-dependent utterances(IU) - 6"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3277</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        text\n",
              "label       \n",
              "0       6009\n",
              "1      18300\n",
              "2      17869\n",
              "3      12968\n",
              "4       1745\n",
              "5       1087\n",
              "6       3277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD4Muf7YhA1i",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing - Emotion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oVN6ccTg1VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "from soynlp.normalizer import *\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "def tokenizer(text): # create a tokenizer function\n",
        "    okt = Okt()\n",
        "    text = only_hangle(text)\n",
        "    text = repeat_normalize(text, num_repeats = 2)\n",
        "    x = okt.morphs(text , stem= True)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOw3Ww5nhGID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words_set = pd.read_csv(path+'stopwords100.txt',header = 0, delimiter = '\\t', quoting = 3)\n",
        "stop_words= (list(stop_words_set['aa']))\n",
        "stop_words2 = ['은', '는', '이', '가', '하', '아', '것', '들','의', '있', '되', '수', '보', '주', '등', '한']\n",
        "stop_words.extend(stop_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMbhpZmuhIRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "SEED = 3432\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "TEXT_emo = data.Field(tokenize=tokenizer, stop_words = stop_words)\n",
        "LABEL_emo = data.LabelField()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA6722Q_kYG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R99Oem4k0St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "fields_emo = [(\"Sentence\", TEXT_emo),(\"Emotion\", LABEL_emo)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HokxYlu_k3oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_emo,valid_emo, test_emo = data.TabularDataset.splits(\n",
        "                                        path = path,\n",
        "                                        train = 'sentiment_train.csv',\n",
        "                                        validation = 'sentiment_valid.csv',\n",
        "                                        test = 'sentiment_test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields_emo,\n",
        "                                        skip_header = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-suCA51k8Gq",
        "colab_type": "code",
        "outputId": "d447f509-9f4f-422a-9cfe-d5b59378cfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vars(train_emo[3])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Emotion': '5', 'Sentence': ['어제', '런닝맨', '완전', '재밌다']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpV_SIrfllGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "vec = torchtext.vocab.Vectors('wiki.ko.vec', cache=path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz6r-BUelogp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT_emo.build_vocab(train_emo, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = vec, \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL_emo.build_vocab(train_emo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EEHQvW8lunB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Iterator, BucketIterator\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator_emo, valid_iterator_emo, test_iterator_emo = data.BucketIterator.splits(\n",
        "    (train_emo, valid_emo, test_emo), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device, sort = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ0BXF_KmDk0",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing - Utterance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qczuf5A64CbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 3432\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT_utt = data.Field(tokenize=tokenizer, stop_words = stop_words)\n",
        "LABEL_utt = data.LabelField()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0wp4Q6Dl8nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields_utt = [(\"text\", TEXT_utt),(\"label\", LABEL_utt)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41qPXuw0maM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_utt,valid_utt, test_utt = data.TabularDataset.splits(\n",
        "                                        path = path,\n",
        "                                        train = 'utterance_train.csv',\n",
        "                                        validation = 'utterance_valid.csv',\n",
        "                                        test = 'utterance_test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields_utt,\n",
        "                                        skip_header = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTRN7TW2mvMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT_utt.build_vocab(train_utt, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = vec, \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL_utt.build_vocab(train_utt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNClEjcUwXg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator_utt, valid_iterator_utt, test_iterator_utt = data.BucketIterator.splits(\n",
        "    (train_utt, valid_utt, test_utt), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device, sort = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYsJjjn6nE_j",
        "colab_type": "text"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyXp6hyjm9ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_emo(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        text = text.permute(1, 0)        \n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoBHi_3pnJkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_utt(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        text = text.permute(1, 0)        \n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKUzNV6AnQPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM_emo = len(TEXT_emo.vocab)\n",
        "OUTPUT_DIM_emo = len(LABEL_emo.vocab)\n",
        "PAD_IDX_emo = TEXT_emo.vocab.stoi[TEXT_emo.pad_token]\n",
        "\n",
        "INPUT_DIM_utt = len(TEXT_utt.vocab)\n",
        "OUTPUT_DIM_utt = len(LABEL_utt.vocab)\n",
        "PAD_IDX_utt = TEXT_utt.vocab.stoi[TEXT_utt.pad_token]\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,4]\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model_emo = CNN_emo(INPUT_DIM_emo, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM_emo, DROPOUT, PAD_IDX_emo)\n",
        "model_utt = CNN_utt(INPUT_DIM_utt, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM_utt, DROPOUT, PAD_IDX_utt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5HzKE_pn9L8",
        "colab_type": "code",
        "outputId": "6fc85a71-91fa-422a-8d75-0f20b9a02409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def count_parameters_emo(model_emo):\n",
        "    return sum(p.numel() for p in model_emo.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters_emo(model_emo):,} trainable parameters')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,058,307 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gku5cb9BoFOt",
        "colab_type": "code",
        "outputId": "01843ba5-56cc-4fe0-bed3-3732882ab283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def count_parameters_utt(model_utt):\n",
        "    return sum(p.numel() for p in model_utt.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters_utt(model_utt):,} trainable parameters')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,218,707 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5hkGTZHoQ5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_embeddings_emo = TEXT_emo.vocab.vectors\n",
        "pretrained_embeddings_utt = TEXT_utt.vocab.vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJx4PmC8oJrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX_emo = TEXT_emo.vocab.stoi[TEXT_emo.unk_token]\n",
        "UNK_IDX_utt = TEXT_utt.vocab.stoi[TEXT_utt.unk_token]\n",
        "\n",
        "model_emo.embedding.weight.data[UNK_IDX_emo] = torch.zeros(EMBEDDING_DIM)\n",
        "model_emo.embedding.weight.data[PAD_IDX_emo] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "model_utt.embedding.weight.data[UNK_IDX_utt] = torch.zeros(EMBEDDING_DIM)\n",
        "model_utt.embedding.weight.data[PAD_IDX_utt] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbpHXbPPo5bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer_emo = optim.Adam(model_emo.parameters())\n",
        "optimizer_utt = optim.Adam(model_utt.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_emo = model_emo.to(device)\n",
        "model_utt = model_utt.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0caTfGaLpEUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLMksDs0pO2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_emo(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.Sentence)\n",
        "        \n",
        "        loss = criterion(predictions, batch.Emotion)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, batch.Emotion)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mykuXo51pTZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model_emo(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.Sentence)\n",
        "            \n",
        "            loss = criterion(predictions, batch.Emotion)\n",
        "            \n",
        "            acc = categorical_accuracy(predictions, batch.Emotion)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31SzjxTbtar3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_utt(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text)        \n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3__scl4ctakR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model_utt(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text)            \n",
        "            loss = criterion(predictions, batch.label)            \n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqcEGa3MpUh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2XsOLCqpXTb",
        "colab_type": "text"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMeltC8PpVru",
        "colab_type": "code",
        "outputId": "12e2b402-6390-428f-f421-5bc469b701eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "#Emotion\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss_emo, train_acc_emo = train_model_emo(model_emo, train_iterator_emo, optimizer_emo, criterion)\n",
        "    valid_loss_emo, valid_acc_emo = evaluate_model_emo(model_emo, valid_iterator_emo, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss_emo < best_valid_loss:\n",
        "        best_valid_loss = valid_loss_emo\n",
        "        torch.save(model_emo.state_dict(), 'emo-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss_emo:.3f} | Train Acc: {train_acc_emo*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss_emo:.3f} |  Val. Acc: {valid_acc_emo*100:.2f}%')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 1.798 | Train Acc: 29.44%\n",
            "\t Val. Loss: 1.557 |  Val. Acc: 39.74%\n",
            "Epoch: 02 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 1.488 | Train Acc: 43.36%\n",
            "\t Val. Loss: 1.522 |  Val. Acc: 40.50%\n",
            "Epoch: 03 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 1.290 | Train Acc: 51.94%\n",
            "\t Val. Loss: 1.562 |  Val. Acc: 40.91%\n",
            "Epoch: 04 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 1.100 | Train Acc: 59.39%\n",
            "\t Val. Loss: 1.595 |  Val. Acc: 41.77%\n",
            "Epoch: 05 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.902 | Train Acc: 67.36%\n",
            "\t Val. Loss: 1.697 |  Val. Acc: 41.57%\n",
            "Epoch: 06 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.739 | Train Acc: 73.72%\n",
            "\t Val. Loss: 1.834 |  Val. Acc: 41.50%\n",
            "Epoch: 07 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.602 | Train Acc: 79.13%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 41.61%\n",
            "Epoch: 08 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.504 | Train Acc: 82.13%\n",
            "\t Val. Loss: 2.163 |  Val. Acc: 41.61%\n",
            "Epoch: 09 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.419 | Train Acc: 85.76%\n",
            "\t Val. Loss: 2.351 |  Val. Acc: 41.60%\n",
            "Epoch: 10 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.363 | Train Acc: 87.55%\n",
            "\t Val. Loss: 2.558 |  Val. Acc: 41.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQIj6z35rXxb",
        "colab_type": "code",
        "outputId": "ecafc3c1-efc6-412a-9c76-29a8376bb414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model_emo.load_state_dict(torch.load('emo-model.pt'))\n",
        "\n",
        "test_loss_emo, test_acc_emo = evaluate_model_emo(model_emo, test_iterator_emo, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss_emo:.3f} | Test Acc: {test_acc_emo*100:.2f}%')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.530 | Test Acc: 40.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrRGaZ9r_b6",
        "colab_type": "code",
        "outputId": "f07bd086-76be-4ea3-8592-a5e54f635ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "#Utterance\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss_utt, train_acc_utt = train_model_utt(model_utt, train_iterator_utt, optimizer_utt, criterion)\n",
        "    valid_loss_utt, valid_acc_utt = evaluate_model_utt(model_utt, valid_iterator_utt, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss_utt < best_valid_loss:\n",
        "        best_valid_loss = valid_loss_utt\n",
        "        torch.save(model_utt.state_dict(), 'utt-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss_utt:.3f} | Train Acc: {train_acc_utt*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss_utt:.3f} |  Val. Acc: {valid_acc_utt*100:.2f}%')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.715 | Train Acc: 73.93%\n",
            "\t Val. Loss: 1.018 |  Val. Acc: 66.53%\n",
            "Epoch: 02 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.612 | Train Acc: 77.51%\n",
            "\t Val. Loss: 1.081 |  Val. Acc: 66.52%\n",
            "Epoch: 03 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.534 | Train Acc: 80.37%\n",
            "\t Val. Loss: 1.142 |  Val. Acc: 66.39%\n",
            "Epoch: 04 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.475 | Train Acc: 82.45%\n",
            "\t Val. Loss: 1.224 |  Val. Acc: 67.41%\n",
            "Epoch: 05 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.430 | Train Acc: 84.22%\n",
            "\t Val. Loss: 1.338 |  Val. Acc: 65.76%\n",
            "Epoch: 06 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.384 | Train Acc: 85.69%\n",
            "\t Val. Loss: 1.418 |  Val. Acc: 66.57%\n",
            "Epoch: 07 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.358 | Train Acc: 86.95%\n",
            "\t Val. Loss: 1.518 |  Val. Acc: 67.62%\n",
            "Epoch: 08 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.332 | Train Acc: 87.66%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 66.28%\n",
            "Epoch: 09 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.315 | Train Acc: 88.50%\n",
            "\t Val. Loss: 1.699 |  Val. Acc: 66.48%\n",
            "Epoch: 10 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.300 | Train Acc: 89.03%\n",
            "\t Val. Loss: 1.790 |  Val. Acc: 66.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LUjWStksw9B",
        "colab_type": "code",
        "outputId": "eff0de90-83b8-4216-a51f-b44f18b61d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model_utt.load_state_dict(torch.load('utt-model.pt'))\n",
        "\n",
        "test_loss_utt, test_acc_utt = evaluate_model_utt(model_utt, test_iterator_utt, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss_utt:.3f} | Test Acc: {test_acc_utt*100:.2f}%')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.032 | Test Acc: 66.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHPaPI-um8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emo(model, sentence, min_len = 4):\n",
        "    model.eval()\n",
        "    # 이 부분에서 그냥 바로 tokenizing\n",
        "    tokenized = tokenizer(sentence)\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT_emo.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    preds = model(tensor)\n",
        "    max_preds = preds.argmax(dim = 1)\n",
        "    return max_preds.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVEAG6tt9Req",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emotion_classifier(logits):\n",
        "  global sentiment\n",
        "  if logits == \"0\":\n",
        "    sentiment = '중립'\n",
        "  elif logits == \"1\":\n",
        "    sentiment = '공포'\n",
        "  elif logits == \"2\":\n",
        "    sentiment = '놀람'\n",
        "  elif logits == \"3\":\n",
        "    sentiment = '분노'\n",
        "  elif logits == \"4\":\n",
        "    sentiment = '슬픔'\n",
        "  elif logits == \"5\":\n",
        "    sentiment = '행복'\n",
        "  elif logits == \"6\":\n",
        "    sentiment = '혐오'\n",
        "\n",
        "  return sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbNHks9b9Saj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_utt(model, sentence, min_len = 4):\n",
        "    model.eval()\n",
        "    # 이 부분에서 그냥 바로 tokenizing\n",
        "    tokenized = tokenizer(sentence)\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT_utt.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    preds = model(tensor)\n",
        "    max_preds = preds.argmax(dim = 1)\n",
        "    return max_preds.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSTCj55V9aYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def utterance_classifier(logits):\n",
        "  global utterance\n",
        "  if logits == \"0\":\n",
        "    utterance = '미완'\n",
        "  elif logits == \"1\":\n",
        "    utterance = '서술'\n",
        "  elif logits == \"2\":\n",
        "    utterance = '질문'\n",
        "  elif logits == \"3\":\n",
        "    utterance = '요구'\n",
        "  elif logits == \"4\":\n",
        "    utterance = '수사의문'\n",
        "  elif logits == \"5\":\n",
        "    utterance = '수사명령'\n",
        "  elif logits == \"6\":\n",
        "    utterance = '억양'\n",
        "\n",
        "  return utterance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lslMJKlj9chh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4b03b537-4af8-48bf-8720-cb19a8686a38"
      },
      "source": [
        "pred_sentence = input()\n",
        "pred_emo = predict_emo(model_emo, pred_sentence)\n",
        "pred_utt = predict_utt(model_utt, pred_sentence)\n",
        "logit_1 = LABEL_emo.vocab.itos[pred_emo]\n",
        "logit_2 = LABEL_utt.vocab.itos[pred_utt]\n",
        "\n",
        "print(f'이 문장의 감정은 {emotion_classifier(logit_1)}이고, 발화 의도는 {utterance_classifier(logit_2)}입니다')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "프로젝트가 마무리되고 있어서 너무 좋다.\n",
            "이 문장의 감정은 행복이고, 발화 의도는 서술입니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hR2QhcM-FQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 이제 Class별로 정확도 구분할 수 있게"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
